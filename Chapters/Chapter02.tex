%*****************************************
\chapter{Background}\label{ch:background}
%*****************************************

This chapter contains text published in the following paper:

\begin{enumerate}
\item Taylor C.J., Pomberger, A., \textbf{Felton, K.}, Grainger R., Barecka, M., Chamberlain, T., Bourne, R.A., Lapkin, A. A. "A Brief Introduction to Chemical Reaction Optimization". \textit{Chemical Reviews}. 2023.
\end{enumerate}

In this chapter, I first review transfer learning and then the introduce two types of machine learning used in this thesis: Bayesian optimization and molecular property prediction. I discuss how transfer learning can be applied to both of these types of machine learning.

\section{Transfer Learning}

The key idea behind transfer learning is to improve the inductive bias of a machine learning model \cite{Zhuang2021}. Inductive bias is the inherent set of assumptions the model makes about the data it is being trained on. Transfer learning creates a better inductive bias for a model using data from a relevant dataset. When effective, transfer learning can enable models to learn from smaller datasets and generalize to unseen examples more effectively. 

In transfer learning, there is a source domain and target domain. The source domain often, but not always, contains more data, while the target domain contains a smaller dataset for the primary task. Two of the most well-known examples of transfer learning are pretrained computer vision models and natural language models. Computer vision deep neural networks such as ResNet \cite{He2016} often are pretrained on large classification datasets containing more than one million images such as Imagenet (i.e., source domain) \cite{Russakovsky2015}, and subsequently can learn to classify new objects on new datsets with as little as thirty images (target domain). Early layers in pretrained neural networks learn the fundamentals of computer vision such as identifying lines and shapes, and later layers can recognize more semantically complex concepts such as faces. This inductive bias learned from the large source dataset enables the neural network to learn from a small number of examples.  Similarly, the revolution of large language models (e.g., the General Pretrained Transformers, GPT, models \cite{Radford2018, Brown2020}) currently happening is spurred by large-scale unsupervised pre-training. In this approach, the source data is a large corpus of text, often extracted from the internet. The neural network is trained to predict the next (or a randomly selected \cite{Delvin2019}) word or paragraph. While conceptually simple, this task forces the model to learn the semantics of language and even some aspects of logic. As a result, when prompted with a new task in a target domain, the model can quickly adapt with a small number of examples.

The challenge of using transfer learning in process development is the lack of large source experimental datasets. Therefore, there is a need for approaches that can leverage sparse and limited data. Three approaches that are promising in this direction are multi-task learning, multifidelity learning and meta-learning.

\subsection{Multi-task Learning}

Multi-task learning is a form of transfer learning that builds one model to predict several related tasks. By leveraging the similarity between the tasks, the multi-task model often achieves more accurate predictions than individual models trained on each task \cite{Simes2018}. As a form of transfer learning, multi-task learning is particularly useful when the amount of data available for each task is limited.

Previously, multi-task learning has found use in several life science applications. Ramsundar and co-workers were the first to complete a detailed study of using multi-task deep learning for predicting the activity of molecules in various biological assays \cite{Ramsundar2015}. They found that increasing the number of tasks results in better performance in most cases, primarily due to active compounds sharing similar mechanisms across tasks. The same authors extended this work by comparing several different deep learning architectures techniques to the gold standard random forests on different pharmaceuticals datasets. They again found that multi-task learning is very effective at improving over random forests, though not always \cite{Ramsundar2017}. In contrast, Sadawi compared various types of multi-task learning in several QSAR datasets and found that random forests often outperformed deep learning models \cite{Sadawi2019}. These results suggest that performance of multi-task learning is highly dependent on the task.

There has also been work examining how multi-task learning can be used for chemical reactions. Struble et al. used a multi-task deep learning model to predict site selectivity of C-H activation reactions, resulting in a accuracy improvement compared single task models \cite{Struble2020}. The accuracy improvement of the multi-task model was attributed to several of the tasks having a small number of examples but high similarity to other tasks. In another study, a multi-task transformer model was used to predict the outcomes of carbohydrate reactions \cite{Pesciullesi2020}. The authors found that training in multi-task mode instead of sequential fine-tuning led to lower error on the test set. 

Recent work has applied multi-task learning to process development related tasks. Schweidtmann et al. used a multi-task graph neural network to predict the ignition quality of fuels used in combustion engines \cite{Schweidtmann2020}. They found that the multi-task model gave better performance than training individual models for each property. Similar results have been found in property prediction for polymers \cite{Gurnani2023}.

\subsection{Multifidelity learning}

Another transfer learning technique is multifidelity learning, which aims to leverage data from a cheap but less accurate data source to help with predicting a more expensive task. The distinction between multifidelity and multi-task learning is often due to the data sources rather than the modeling techniques. In multifidelity modeling, the source task often has significantly more data than the target task. Often, the source task is a simulation, while the target task is an experiment. 

For example, Greenman et al recently used multifdielity modeling to improve predictions of optical properties of molecules \cite{Greenman2022}. They first trained a model on data from QM calculations and then used the predictions of the DFT trained model as input to a model solely trained on a limited set of experimental data. Including the predictions of the model trained on QM calculations significantly improved performance of the model. Similar approaches have been applied in a wide range of scenarios including parameter estimation of physics models using data from multiple experiments and simulations;\cite{Perdikaris2016} optimizing battery electrode structure using data from both cheap and expensive multitscale differential equation models \cite{Pan2017}, and optimizing composition of alloys using a mix of DFT fidelities \cite{Tran2020}. In Chapter \ref{ch:mfbo}, I explore how multifidelity modeling can be used in the context of controller tuning.

\subsection{Meta-learning}

Informally, meta-learning is the process of learning how to learn. The difference in this approach is the training process explicitly includes a loss function that aims to create fast learning. Most existing approaches rely primarily on learning metrics for better classification, but a recent set of methods based on optimization are more relevant to process development.  In this case, the aim is to adjust gradient based optimization to train a model such that minimizing the loss will require the minimium number of steps. There are a wide variety of techniques in this family including model agnostic meta-learning (MAML) \cite{Finn2017}, REPTILE \cite{Nichols2018} and Platipus \cite{Finn2018}. While I do not explore meta-learning in this thesis, it is a promising direction for future work in accelerating process development.



\section{Bayesian optimization}

Bayesian optimization (BO) is a method for optimizing expensive to evaluate functions \cite{Shahriari2016}. In our case, these "functions" are experiments or long-running simulations. More formally, BO aims to solve the optimization problem.
\begin{equation}
    \max_x y(x)
\end{equation}
where $y(x)$ is the underlying function that are observed via time-consuming or costly experiments. Bayesian optimization (BO) is designed to optimize $y$ with as few experiments as possible. It does this by first training a surrogate probabilistic model to represent the underlying function and, then, optimizing an acquisition function informed by this model to choose next experiments. Typically, the probabilistic model is a Gaussian Process (GP). 

\subsection{Gaussian Processes}

A GP is a stochastic process characterized by a mean function $\mu(x)$ and covariance function $k_{\theta}(x,x')$ \cite{Rasmussen2006}. The covariance function is often called a kernel, which is the term I will use henceforth.

\begin{equation}
    f(x)= \mathcal{GP}(\mu(x), k_{\theta}(x, x'))
\end{equation}

$\theta$ are referred to as the hyperparameters of the GP and are varied to train the GP. Given a finite set of $N$ inputs $\mathbf X = \{\mathbf x_1, \mathbf x_2, \dots, \mathbf x_N \ \vert x_i \in \mathbb R^m \}$ that correspond with outputs $\mathbf y = \{y_1, y_2, \dots y_N \vert  y_i \in \mathbb R \}$, the GP is a multivariate Gaussian distribution:

\begin{equation}
    f(\mathbf X) \sim \mathcal N(\mu_{\theta}(\mathbf X), k_{\theta}(\mathbf X, \mathbf X'))
\end{equation}

The mean function and kernel act as a prior on the GP.  $\mu_{\theta}(x)$ is usually set to zero because the kernel  $k_{\theta}(x, x')$ can expressively represent any arbitrary function. In this work, I use the Matérn 5/2 kernel, with hyperparameters $\theta=\{\sigma,\mathbf L \}$. $\sigma \in \mathbb R$ is the scaling hyperparameter and $\mathbf L \in \mathbb R^m$ is a lengthscale that indicates the significance of each input feature:
\begin{equation}
    k_{\theta}(x, x') = \sigma^2 \biggl(1 + \sqrt{5}d_{\theta}(x,x')+\frac{5}{3}d_{\theta}(x,x')^2\biggr)\exp\biggl(-\sqrt{5}d_{\theta}(x,x') \biggr)
\end{equation}
$d_{\theta}(x,x')$ is the euclidean distance weighted by the lengthscale.
\begin{equation}
    d_{\theta}(x,x')=\biggl\lVert \frac{x-x'}{L} \biggr\rVert_2
\end{equation}
Inference on the GP is done by calculating the posterior of the GP. The posterior of the GP is also a Gaussian distribution:

\begin{equation}
     \tilde f(\mathbf X) \sim \mathcal N(\tilde \mu(\mathbf X), \tilde \sigma_{\theta}(\mathbf X, \mathbf X'))
\end{equation}

\begin{equation}
    \tilde \mu_{\theta}(x) = k_{\theta}(x, \mathbf X)k_{\theta}(\mathbf X, \mathbf X')^{-1} \mathbf y
\end{equation}

\begin{equation}
    \tilde k_{\theta}(x,x') = k_{\theta}( x, x')-k_{\theta}(x, \mathbf X) k_{\theta}(\mathbf X, \mathbf X)^{-1}k_{\theta}(\mathbf X, x)
\end{equation}
where $\tilde \sigma_{\theta}(x)$ are the diagonals of the covariance matrix calculated using $\tilde k_{\theta}(x, x')$.
To train the GP, the log likelihood is maximized, which is the probability that the model predicts the training outputs given the inputs and hyperparameters. The log likelihood avoids overfitting by trading off accuracy of fit to the training data and complexity of the model.
\begin{equation}
\begin{split}
    \log p(y \vert X, \theta) = & -\underbrace{\frac{1}{2}(y-\tilde \mu_{\theta}(\mathbf X))^T k_{\theta}(\mathbf X, \mathbf X)^{-1}(y- \tilde\mu_{\theta}(\mathbf X)) }_{\text{Data  fit}} \\
    & - \underbrace{\frac{1}{2} \log{\vert \tilde k_{\theta}(\mathbf X, \mathbf X) \vert} - \frac{d}{2}\log{2 \pi}}_{\text{Complexity penalty}}
\end{split}
\end{equation}

\subsection{Acquisition Functions}

The most commonly used acquisition function is the expected improvement (EI). In BO with EI as an acquisition function, the aim is to choose the point that is expected to improve the most upon the existing best observed point $y^* \geq \hat y(x_i) \forall i \in (1, \dots, t)$  where  $t$ is the number of observations thus far. Therefore, I create an improvement function $I(x)$ describing the improvement of the posterior of the GP over the best observed point. If there is no improvement, $I(x)=0$.
\begin{equation}
    I(x) = \max(\tilde f_{\theta}(x) -y^*, 0)
\end{equation}
For EI, I want the expectation of the improvement:
\begin{equation}
    EI(x) = \mathbb E_{y}[I(x)]
\end{equation}
After some manipulations, the following closed form for the expected improvement is found:
\begin{equation}
    EI(x) =(\tilde \mu_{\theta}(x)-\hat y^*)\Phi(Z^*) + \tilde \sigma_{\theta}(x) \phi(Z^*)
\end{equation}
where $Z^*= \frac{y^*-\tilde\mu_{\theta}(x)}{\tilde \sigma_{\theta}(x)}$.  I then solve the following optimization problem to select the next experiment $x_{next}$.
\begin{equation}
    x_{\text{next}} = \text{argmax}_{x} EI(x)
\end{equation}
Since EI has a closed analytical for the expectation and derivative, gradient based second-order optimization algorithms are typically used. 

While EI is a good baseline acquisition function, it can be overly exploitative, especially in the presence of noisy or inaccurate predictions from the GP.  Noisy EI (NEI) improves upon this by sampling the expectation of the acquisition function and the posterior probability, which reduces uncertainty in the optimum \cite{Letham2019}. A robust and efficient impelementation of the NEI that uses a full Monte-Carlo treatment is available in the software package BoTorch \cite{Balandat2020}:
\begin{equation}
qNEI(x)= E[(\max \xi  - \max \xi_{obs} )_+]
\end{equation}
where $\xi_{obs} f(x)$ and $\xi_{obs}\sim f(x)$ are samples from the posterior of the GP.

\subsection{Transfer learning for Bayesian optimization}

The most common approach to transfer learning in BO is improving the probabilistic model by leveraging information for auxiliary tasks. I will review two methods for improving  Gaussian processes: multi-task BO and multi-fidelity BO.

One of the potential ways to accelerate Bayesian optimization is multi-task Bayesian optimization (MTBO). MTBO was originally developed to speed up hyperparameter tuning of machine learning models (e.g., choosing learning rates and batch sizes to maximize model accuracy) \cite{Swersky2013}. Using only the hyperparameters and resulting model accuracy scores of a previously trained machine learning model (which I call Task A),  MTBO decreased by up to 50\% the the number of experiments needed to find optimal hyperparameters for a new machine learning model (which I call Task B).  The data from Task A helped the model better predict Task B, even with only a few experiments for Task B.

Multi-task Bayesian optimization (MTBO) uses a multi-task probabilistic model inside a BO framework.  Swersky et al. were the first to demonstrate that multi-task BO can be effectively used to accelerate BO for hyperparameter tuning of machine learning models \cite{Swersky2013}. They demonstrated that using the results of hyperparameter tuning on one dataset could assist in tuning another with multi-task GPs. In many cases, multi-task BO could achieve 40-50\% improvements in the test accuracy of models with significantly fewer training runs.  

One of the challenges faced in applying MTBO to big data uses cases has been its lack of scalability. This in mainly due to the $O(n^3)$ cost of using GPs with exact inference. Several different approaches have been taken to solving this problem including training a vanilla neural network on the tasks and feeding the output to a Bayesian linear regression model \cite{Perrone2018} and using the auxiliary tasks to create a learned feature representation in a compressed space \cite{Hakhamaneshi2021}. These methods have retained the performance of multi-task BO while minimizing the computational cost of its deployment. However, in this thesis, all applications of MTBO have less than 1000 points and in many cases, less than 100. This makes multi-task GPs with exact inference more tractable.

Another direction has been to apply the machinery of multi-task GPs to multifidelity BO, which aims to leverage data from a cheap but less accurate data source to help with optimizing a more expensive function \cite{Huang2006, Forrester2007}. This technique has been applied in a wide range of scenarios including parameter estimation of physics models using data from multiple experiments and simulations \cite{Perdikaris2016}; optimizing battery electrode structure using data from both cheap and expensive multitscale differential equation models \cite{Pan2017, Folch2023}, and optimizing composition of alloys using a mix of DFT fidelities \cite{Tran2020}. I explore this idea in chapter \ref{ch:mfbo}.

\section{Molecular Property Prediction}

In addition to Bayesian optimization, I use molecular property prediction techinques in Part II.

\subsection{Molecular Parameterization}

The first step of making machine learning models that can predict molecular properties is translating molecules to a machine-readable, typically numerical, format that can be used as input for ML models. This translation process is molecular parameterization as it aims to capture relevant molecular properties for a particular reaction. For different chemical transformations, molecular parametrizations should capture different properties such as steric hinderance of a functional group or electronegativity of neighboring atoms. The parameterization strategy should also be chosen to allow optimal compatibility with the ML model used, as prediction performance will depend on the compatibility between input format and ML model.

The baseline parameterization method for representing chemical inputs is one-hot encoding (OHE). A one (1) or a zero (0) represent the presence or absence of specified reaction components respectively - no chemical information is encoded. This approach has been shown to be effective for a variety of chemical tasks including yield prediction, but cannot extrapolate to new parts of chemical space \cite{Pomberger2023}. 

Extended-connectivity fingerprints (ECFP) is a parameterization method that captures atom types, neighboring connectivity relationships, bond types and represents the outcome in a machine-readable one-dimensional bit-vector \cite{Rogers2010}. Circular fingerprints (e.g. Morgan fingerprints) are generated by: 1) assigning identifiers to each atom in the molecule, 2) updating each atom’s identifiers depending on the neighboring atoms, 3) removing duplicates and 4) compressing the data into a vector of set length e.g. 1024 bit (a number of zeros and ones). One of the advantages of these fingerprint based methods is that they are considered cheap features for modelling; their generation does not require vast amount of computing power/time. Yet, their ability to explicitly capture molecular properties (e.g., sterics, electronics) of molecules is limited. Typically, models that use fingerprints develop knowledge in an indirect manner, such as an implicit understanding of electronegativity associated with different halides \cite{Eyke2020}.

A much more comprehensive parameterization approach is calculating molecular descriptors using density functional theory (DFT). DFT can be used to determine the ground/excited state of molecules and thus offer fundamental insights into geometric and electronic properties \cite{Shields2021}. As a result, DFT can be used to calculate descriptors that quantify the specific chemical properties of the given set of ligands such as the bulkiness of a molecule or electronegativity of atoms within a molecule. However, DFT calculations for large libraries are often more time-consuming than actually running the corresponding reactions in a high-throughput screening format.

More recently, parameterization work has utilized neural networks to achieve the tailored nature of DFT descriptors without the computational expense. This work is divided into two approaches: natural language processing models and graph neural networks. The former leverages recent advances in language models such as transformers \cite{Vaswani2017}, where results can be achieved by training a model to predict the next word in a sentence across a wide variety of text. Since chemistry can be represented as a language in the form of simplified molecular-input line-entry system (SMILES) \cite{Weininger1988}, a language model can be trained to predict the next atom in a molecule when given only a portion of the molecule, thereby saving computational expense \cite{Schwaller2019}. Since the model must understand a significant volume of chemistry to be able to predict a SMILES string, its numerical output can be used as a “learned fingerprint” for other prediction tasks \cite{Schwaller2021}.

Furthermore, the learned fingerprint can be tuned for each downstream task such as yield prediction using standard neural network training. Alternatively, graph neural networks represent a molecule as an interconnected network of atoms and bonds. These networks can be trained to produce a “learned fingerprint” for prediction tasks. One of the most widely used forms of graph neural networks in chemistry are message passing neural networks, which are detailed in the following section.

An overview of the techniques covered in this section are shown in Table \ref{tab:parameterization}.

\begin{sidewaystable}
    \caption{Overview of the commonly used molecular parameterization techniques for modelling chemical data.}
    \begin{tabular}{cp{0.25\linewidth}cc}
         Parameterization
    Method & Information Captured & Data Type & Example Data  \\
        \hline
         OHE & Existence/absence of a molecule & Binary encoding & [0 0 0 1 0 0 0 ] \\
         Molecular fingerprints & Atom type, atom count, chemical structure, connectivity & Binary encoding & [1 0 0 1 1 0 1 0 0 … 0 1] \\
         DFT descriptors & Inter atomic information: length, angles, volumes &  Numerical values & 0.001342, 45, $\dots$ \\
         Learned representations & Connectivity and potentially atom and bond & Numerical values & 0.001342, 45, $\dots$
    \end{tabular}
    \label{tab:parameterization}
\end{sidewaystable}

\subsection{Deep Learning Architectures}

Molecules can be treated as graphs with atoms as nodes and bonds as edges. Therefore, message passing neural networks (MPNN) that operate on graphs can be used to create learned representations of molecules \cite{Gilmer2017}.  In a MPNN, each atom has associated node features $x_v$ such as atomic number and formal charge, and each bond has associated edge features $e_{vw}$ such as bond degree (single, double, triple). A hidden representation can be generated for each atom $h_t$, and  during a forward pass, messages are created as follows:
\begin{equation}
    m_v^{t+1} = \sum_{w\in N(v)} M_t(h_v^t, h_w^t, e_{vw})
\end{equation}

\begin{equation}
    h_v^{t+1} = U_t(h_v^t, m_v^{t+1})
\end{equation}
where $M_t$ is the message function, $U_t$ is the update function and $h_v^{t}$ is the hidden state at step $t$. This update process is repeated several times (usually two to three) and the representations from all atoms are aggregrated, usually using a sum or mean:
\begin{equation}
    \bar h = \sum_{v\forall \mathcal V} h_v
\end{equation}

To obtain predictions $\hat y$, the outputs of the last message passing step $T$ are passed through a feed forward network $R$ in a readout phase:

\begin{equation}
    \hat y = R(h_v^T \in G)
\end{equation}

This  vector is called a message. In each layer, a permutation invariant aggregation function such as the mean is used to calculate the total message for each node prior to passing through an activation function to get a new value for each node.  In contrast to traditional fixed fingerprints like ECFP \cite{Rogers2010}, the best feature vector is learned end-to-end for each property prediction task.

\subsection{Transfer Learning for Molecular Property Prediction}

Most transfer learning work for molecular property prediction centers around pre-training. There is work on both self-supervised and supervised approaches.

The self-supervised approaches generally try to improve the representations learned by MPNNs using unlabeled data. Since there are large databases of existing molecules (e.g., ZINC with 1B+ molecules \cite{Irwin2020}), a large-scale pre-training task similar to those used for language modeling can be constructed. For example, Hu et al. masked missing atom nodes from molecular graphs and created a task of predicting the missing nodes \cite{Hu2020Pretrain}. By combining this pre-training task with a supervised pre-training on molecular properties, they obtained state-of-the-art results at the time of publication on some benchmark tasks. While self-supervised approaches are promising, they do not always result in

Supervised approaches usually train a full network on previous data, fix the message passing encoder and only train the feed forward network on subsequent data. For example, Vermeire et al used such an approach to improve predictions of solvation free energies by first pretraining on a large database of calculations from the thermodynamic programme COSMO-RS and subsequently fine-tuning on experimental data \cite{Vermeire2021}. 

\section{Conclusions}

In this thesis, transfer learning is examined in two modes: multi-task learning, multifidelty learning and pre-training. These general strategies are overlaid on the machine learning approaches of Bayesian optimization and molecular property prediction using deep learning. 